{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Work Flow\n",
    "\n",
    "1. x_train: \\[text1, text2, ...\\]\n",
    "   y_train: \\[label1, label2, ...\\]\n",
    "\n",
    "2. Use x_train to generate vocabulary set (6432,) and get token_to_id map. This map will map a word to an index in vocabulary space. Transform text to \\[index1, index2, ..., \\]. \n",
    "\n",
    "    Unknown word is UNK, padding to fixed length vector using PAD.\n",
    "    \n",
    "3. Feed into Embedding layer -> LSTM -> Dense Layer\n",
    "\n",
    "The accuracy is 0.986."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Extract data from pickle files ==========\n"
     ]
    }
   ],
   "source": [
    "from src.data_preprocess.preprocess import DataProcessor\n",
    "data_preprocessor = DataProcessor()\n",
    "train_documents, test_documents = data_preprocessor.get_train_and_test_documents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7310, 7310, 3347, 3347)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "bag_of_classes = set()\n",
    "\n",
    "for document in train_documents:\n",
    "    bag_of_classes.add(document.class_list[0])\n",
    "    x_train.append(' '.join(word_tokenize(document.text)))\n",
    "    y_train.append({'label': document.class_list[0]})\n",
    "        \n",
    "for document in test_documents:\n",
    "    for class_ in document.class_list:\n",
    "        if class_ in bag_of_classes:\n",
    "            x_test.append(' '.join(word_tokenize(document.text)))\n",
    "            y_test.append({'label': class_})\n",
    "            break\n",
    "\n",
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counts = Counter()\n",
    "for text in x_train:\n",
    "    token_counts.update(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique tokens : 42000\n",
      "('the', 47506)\n",
      "(',', 45806)\n",
      "('.', 32917)\n",
      "('of', 25521)\n",
      "('to', 25291)\n",
      "...\n",
      "('a.h.a', 1)\n",
      "('brampton', 1)\n",
      "('1,916,000', 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Total unique tokens :\", len(token_counts))\n",
    "print('\\n'.join(map(str, token_counts.most_common(n=5))))\n",
    "print('...')\n",
    "print('\\n'.join(map(str, token_counts.most_common()[-3:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Word counts')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see how many words are there for each count\n",
    "plt.hist(list(token_counts.values()), range=[0, 10**4], bins=50, log=True)\n",
    "plt.xlabel(\"Word counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# model = api.load('glove-twitter-100')\n",
    "\n",
    "min_count = 10\n",
    "\n",
    "# tokens = []\n",
    "# for token, count in token_counts.items():\n",
    "#     if count >= min_count and token in model.vocab:\n",
    "#         tokens.append(token)\n",
    "\n",
    "tokens = [token for token, count in token_counts.items() if count >= min_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6432\n"
     ]
    }
   ],
   "source": [
    "# Add a special tokens for unknown and empty words\n",
    "UNK, PAD = \"UNK\", \"PAD\"\n",
    "tokens = [UNK, PAD] + sorted(tokens)\n",
    "print(\"Vocabulary size:\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_to_id = {token: i for i, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IX, PAD_IX = map(token_to_id.get, [UNK, PAD])\n",
    "\n",
    "def as_matrix(sequences, max_len=None):\n",
    "    \"\"\"Convert a list of tokens into a matrix with padding \"\"\"\n",
    "    \n",
    "    if isinstance(sequences[0], str):\n",
    "        sequences = list(map(str.split, sequences))\n",
    "        \n",
    "    max_len = min(max(map(len, sequences)), max_len or float('inf'))\n",
    "    \n",
    "    matrix = np.full((len(sequences), max_len), np.int32(PAD_IX))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        row_ix = [token_to_id.get(word, UNK_IX) for word in seq[:max_len]]\n",
    "        matrix[i, :len(row_ix)] = row_ix\n",
    "        \n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:\n",
      "& # 2 ; u.s. economic data key to debt futures outlook by brad schade , reuters chicago , march 11 - u.s. economic data this week could be the key in determining whether u.s. interest rate futures break out of a 3-1/2 month trading range , financial analysts said . although market expectations are for february u.s. retail sales thursday and industrial production friday to show healthy gains , figures within or slightly below expectations would be positive for the market , the analysts said . `` you have to be impressed with the resiliency of bonds right now , '' said smith barney harris upham analyst craig sloane . treasury bond futures came under pressure today which traders linked to a persistently firm federal funds rate and a rise in oil prices . however , when sufficient selling interest to break below chart support in the june contract failed to materialize , participants who had sold bond futures early quickly covered short positions , they said . `` everyone is expecting strong numbers , and if they come in as expected it wo n't be that bad for the market , '' sloane said . sloane said the consensus estimate for the non-auto sector of retail sales is for a rise of 0.6 to 0.7 pct . dean witter analyst karen gibbs said a retail sales figure below market forecasts would give a boost to debt futures , and she put the range for the non-auto sector of retail sales at up 0.8 to 1.2 pct . industrial production and the producer price index friday both are expected to show increases of about 0.5 pct , she added . retail sales `` will tell us whether or not we will be able to fill the gap , '' gibbs said , referring to a chart gap in june bonds between 100-26/32 and 101-3/32 created friday . june bonds closed at 100-4/32 today . also key to debt futures direction , in addition to the federal funds rate , is the direction of crude oil prices , said carroll mcentee and mcginley futures analyst brian singer . `` a higher fed funds rate and firm oil prices precluded the market from breaking out of the trading range the last time the market approached the top of the range , '' singer said . in order for bonds to break above the top of the range , which is just below 102 in the june contract , `` the crude oil rally needs to run its course and pull back a little bit , '' singer said . `` fed funds are already easing back down toward the six pct level . '' the recent surge in oil prices has also been a concern to manufacturers hanover futures analyst jim rozich , but the rally may be nearing a top around 18.50 dlrs per barrel , he said . rozich said he is looking for the june bond contract to ease to 99-6/32 and find support . `` i 'm not quite ready to jump on the bullish bandwagon yet . the jury is still out this week , '' rozich said . reuter & # 3 ;\n",
      "& # 2 ; analysts see early one point cut in u.k. base rate london , march 17 - british bank base lending rates are likely to fall by as much as one full point to 9-1/2 pct this week following the sharp three billion stg cut in the u.k. central government borrowing target to four billion stg set in today 's 1987 budget , bank analysts said . the analysts described chancellor of the exchequer nigel lawson 's budget as cautious , a quality which currency and money markets had already started to reward . sterling surged on foreign exchange markets and money market interest rates moved sharply lower as news of the budget measures came through , the analysts said . lloyds merchant bank chief economist roger bootle said he expected base rates to be cut by one full point tomorrow . `` this is very much a safety-first budget in order to get interest rates down , '' he said . bootle said the money markets had almost entirely discounted such a one point cut , with the key three month interbank rate down to 9-11/16 pct from 9-13/16 last night , and it would be rather conservative for banks to go for a half-point cut now . midland bank treasury economist david simmonds said he , too , expected base rates would be a full point lower by friday , but this would likely happen via two half-point cuts . `` this budget is designed to please both the markets and the electorate . the implications for interest rates are very favourable , we could have a half-point cut tomrorow and another such cut before the end of the week , '' simmonds said . pointing to buoyant u.k. retail data released yesterday , he said lawson had done well to resist pressures for a sharp cut in income tax rates at the expense of a lower borrowing target . `` there is no real need to boost private consumption , '' he said . national westminster bank chief economist david kern said the lower borrowing target set in the budget had increased the likelihood of an early one-point base rate cut . kern said the budget would have to be analysed carefully , in particular to see how exactly lawson planned to achieve the sharper than expected borrowing target cut , before a one-point base rate cut could be implemented . but providing the budget small-print was convincing , `` and i suspect it will be , it is entirely possible that we see one point off base rates by the end of this week , '' kern said . bootle of lloyds said the expected base rate cut would pave the way for an early one-point cut in mortgage lending rates . this would help achieve lawson 's lower than expected consumer price inflation target of four pct at end-1987 , he said . u.k. base rates were cut last week to 10-1/2 pct from 11 pct after sustained pressure from the foreign exchange , money and government bonds ( gilts ) markets . but building societies said they would not cut lending rates until base rates had fallen by one full point . reuter & # 3 ;\n",
      "& # 2 ; stone & lt ; sto > splits stock , raises payout chicago , march 2 - stone container corp said it is splitting its common stock 2-for-1 and increasing its dividend 33-1/3 pct . the dividend of 20 cts a share , an increase of five cts over the prior 15 cts a share on pre-split shares , is payable june 12 to holders of record may 22. the stock split also is payable june 12 to holders of record may 22. reuter & # 3 ;\n",
      "\n",
      "Matrix:\n",
      "[[  3   2 343 ...   1   1   1]\n",
      " [  3   2 343 ...   2 473 759]\n",
      " [  3   2 343 ...   1   1   1]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lines:\")\n",
    "print('\\n'.join(x_train[::3000]), end='\\n\\n')\n",
    "print(\"Matrix:\")\n",
    "print(as_matrix(x_train[::3000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DictVectorizer(dtype=<class 'numpy.float32'>, separator='=', sort=True,\n",
       "        sparse=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categorical_vectorizer = DictVectorizer(dtype=np.float32, sparse=False)\n",
    "categorical_vectorizer.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]], dtype=float32), (3347, 73))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_vector = categorical_vectorizer.transform(y_train)\n",
    "y_test_vector = categorical_vectorizer.transform(y_test)\n",
    "y_train_vector[::300], y_test_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(x, y, max_len=None, word_dropout=0):\n",
    "    \"\"\"\n",
    "    Creates a keras-friendly dict from the batch data.\n",
    "    \"\"\"\n",
    "    \n",
    "    batch = {}\n",
    "    batch['Text'] = as_matrix(x, max_len)\n",
    "    batch['Label'] = y\n",
    "    \n",
    "    if word_dropout != 0:\n",
    "        batch[\"Text\"] = apply_word_dropout(batch[\"Text\"], 1. - word_dropout)\n",
    "    \n",
    "    return batch\n",
    "\n",
    "def apply_word_dropout(matrix, keep_prop, replace_with=UNK_IX, pad_ix=PAD_IX):\n",
    "    dropout_mask = np.random.choice(2, np.shape(matrix), p=[keep_prop, 1 - keep_prop])\n",
    "    dropout_mask &= matrix != pad_ix\n",
    "    return np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train_X, val_x, data_train_y, val_y = train_test_split(as_matrix(x_train, None), y_train_vector, test_size=0.2, random_state=65)\n",
    "\n",
    "data_test_X = as_matrix(x_test, None)\n",
    "data_test_y = y_test_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1462, 1462, 5848)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_x), len(val_y), len(data_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.layers as L\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(L.Embedding(len(tokens), 128))\n",
    "model.add(L.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(L.Dense(y_train_vector.shape[1], activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5848 samples, validate on 1462 samples\n",
      "Epoch 1/10\n",
      "5848/5848 [==============================] - 296s 51ms/step - loss: 0.4389 - acc: 0.8905 - val_loss: 0.1120 - val_acc: 0.9863\n",
      "Epoch 2/10\n",
      " 256/5848 [>.............................] - ETA: 3:55 - loss: 0.1126 - acc: 0.9863"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-e8b244d77b0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m           validation_data=(val_x, val_y))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/AI/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 10\n",
    "\n",
    "model.fit(data_train_X, \n",
    "          data_train_y,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3347/3347 [==============================] - 64s 19ms/step\n",
      "Test score: 0.09097513968299174\n",
      "Test accuracy: 0.9863013621761366\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(data_test_X, data_test_y, batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
