{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification with word embedding\n",
    "\n",
    "sequences matrix → 直接将所有单词的词向量相加\n",
    "\n",
    "效果比较差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Extract data from pickle files ==========\n"
     ]
    }
   ],
   "source": [
    "from src.data_preprocess.preprocess import DataProcessor\n",
    "\n",
    "data_processor = DataProcessor()\n",
    "train_documents, test_documents = data_processor.get_train_and_test_documents()\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "\n",
    "for i, document in enumerate(train_documents):\n",
    "    for j, label in enumerate(document.class_list):\n",
    "        x_train.append(document.text)\n",
    "        y_train.append(label)\n",
    "\n",
    "for i, document in enumerate(test_documents):\n",
    "    x_test.append(document.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tokenizer = WordPunctTokenizer()\n",
    "\n",
    "data_tok = [tokenizer.tokenize(d.lower()) for d in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "model = api.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_phrase_embedding(phrase):\n",
    "    \"\"\"\n",
    "    Convert phrase to a vector by aggregating it's word embeddings. Just take an \n",
    "    average of vectors for all tokens in the phrase with some weights.\n",
    "    \"\"\"\n",
    "    \n",
    "    vector = np.zeros([model.vector_size], dtype='float32')\n",
    "    \n",
    "    # 1. lowercase phrase\n",
    "    phrase = phrase.lower()\n",
    "    \n",
    "    # 2. tokenize phrase\n",
    "    phrase_tokens = tokenizer.tokenize(phrase)\n",
    "    \n",
    "    # 3. average word vectors for all words in tokenized phrase, skip words that are not in model's vocabulary\n",
    "    divisor = 0\n",
    "    for word in phrase_tokens:\n",
    "        if word in model.vocab:\n",
    "            divisor += 1\n",
    "            vector = vector + model.get_vector(word)\n",
    "    \n",
    "    if divisor != 0: vector /= divisor\n",
    "    \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_matrix_x_train = list(map(get_phrase_embedding, x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_matrix_x_test = list(map(get_phrase_embedding, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gjxhlan/anaconda3/envs/AI/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from src.metric.metric import cal_predict_accuracy\n",
    "svm_model = SVC()\n",
    "\n",
    "svm_model.fit(vector_matrix_x_train, y_train)\n",
    "y_pred = svm_model.predict(vector_matrix_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5696391291380853\n",
      "0.5696391291380853\n"
     ]
    }
   ],
   "source": [
    "print(cal_predict_accuracy(y_pred=y_pred, test_documents=test_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
